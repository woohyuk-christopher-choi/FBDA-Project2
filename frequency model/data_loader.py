"""
Data Loader for Low-Beta Anomaly Research

This module provides utilities to:
1. Load cryptocurrency data from Binance/Upbit
2. Load equity data 
3. Create market benchmarks
4. Prepare data for TARV beta estimation

Expected data structure:
- data/binance/{symbol}_1m.arrow  (1-minute candles)
- data/upbit/{symbol}_1m.arrow
- data/equities/{symbol}_1m.arrow
"""

import os
import numpy as np
import pandas as pd
import pyarrow.ipc as ipc  # [ìˆ˜ì •ë¨] PyArrow IPC ëª¨ë“ˆ ì¶”ê°€
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union
from datetime import datetime, timedelta
from dataclasses import dataclass


@dataclass
class DataConfig:
    """Configuration for data loading."""
    data_dir: str = "data"
    exchange: str = "binance"  # 'binance', 'upbit', 'equities'
    frequency: str = "1m"       # '1m', '5m', '15m', '1h', '1d'
    start_date: Optional[str] = None
    end_date: Optional[str] = None

class CryptoDataLoader:
    """
    Load and prepare cryptocurrency data for analysis.
    Handles nested directory structure: data/{exchange}/{symbol}/{exchange}_{symbol}_{freq}.arrow
    """
    
    def __init__(self, config: DataConfig):
        self.config = config
        # base_pathëŠ” data/binance ê¹Œì§€ë¥¼ ê°€ë¦¬í‚´
        self.base_path = Path(config.data_dir) / config.exchange 
        
    def get_available_symbols(self) -> List[str]:
        """Get list of available symbols by checking subdirectories."""
        if not self.base_path.exists():
            print(f"âš ï¸  Data directory not found: {self.base_path}")
            return []
        
        symbols = []
        
        # data/binance/ í´ë” ë‚´ë¶€ì˜ ëª¨ë“  í•­ëª©ì„ ìˆœíšŒ
        for item in self.base_path.iterdir():
            # í•­ëª©ì´ ë””ë ‰í† ë¦¬ì¸ì§€ í™•ì¸ (ì˜ˆ: ADAUSDT í´ë”)
            if item.is_dir():
                symbol = item.name  # í´ë” ì´ë¦„ì´ ê³§ ì‹¬ë³¼ (ì˜ˆ: ADAUSDT)
                
                # í•´ë‹¹ í´ë” ì•ˆì— ìš°ë¦¬ê°€ ì›í•˜ëŠ” 1m íŒŒì¼ì´ ì‹¤ì œë¡œ ìˆëŠ”ì§€ í™•ì¸
                # ì˜ˆìƒ íŒŒì¼ëª…: binance_ADAUSDT_1m.arrow
                expected_filename = f"{self.config.exchange}_{symbol}_{self.config.frequency}.arrow"
                expected_filepath = item / expected_filename
                
                if expected_filepath.exists():
                    symbols.append(symbol)
        
        return sorted(symbols)
    
    def load_symbol(
        self, 
        symbol: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None
    ) -> Optional[pd.DataFrame]:
        """
        Load data for a single symbol.
        """
        # íŒŒì¼ ê²½ë¡œ êµ¬ì„± ìˆ˜ì •:
        # data/binance/{symbol}/binance_{symbol}_1m.arrow
        filename = f"{self.config.exchange}_{symbol}_{self.config.frequency}.arrow"
        filepath = self.base_path / symbol / filename
        
        if not filepath.exists():
            print(f"âš ï¸  File not found: {filepath}")
            return None
        
        try:
            # PyArrow IPC ë°©ì‹ìœ¼ë¡œ íŒŒì¼ ì½ê¸°
            with open(filepath, 'rb') as f:
                reader = ipc.open_file(f)
                table = reader.read_all()
                df = table.to_pandas()
            
            # Ensure datetime index
            if 'datetime' in df.columns:
                df['datetime'] = pd.to_datetime(df['datetime'])
                df.set_index('datetime', inplace=True)
            elif 'timestamp' in df.columns:
                df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')
                df.set_index('datetime', inplace=True)
            elif 'open_time' in df.columns:
                df['datetime'] = pd.to_datetime(df['open_time'], unit='ms')
                df.set_index('datetime', inplace=True)
            
            # Filter by date range
            start = start_date or self.config.start_date
            end = end_date or self.config.end_date
            
            if start:
                df = df[df.index >= start]
            if end:
                df = df[df.index <= end]
            
            return df
            
        except Exception as e:
            print(f"âŒ Error loading {filepath}: {e}")
            return None
    
    # ... ë‚˜ë¨¸ì§€ ë©”ì„œë“œ(load_multiple_symbols, calculate_returns)ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ ...
    def load_multiple_symbols(
        self,
        symbols: List[str],
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        price_column: str = 'close'
    ) -> pd.DataFrame:
        prices = {}
        for symbol in symbols:
            df = self.load_symbol(symbol, start_date, end_date)
            if df is not None and price_column in df.columns:
                prices[symbol] = df[price_column]
        if not prices:
            return pd.DataFrame()
        prices_df = pd.DataFrame(prices)
        prices_df = prices_df.ffill(limit=5)
        return prices_df

    def calculate_returns(
        self,
        prices: pd.DataFrame,
        method: str = 'log'
    ) -> pd.DataFrame:
        """
        Calculate returns from prices.
        Strictly uses 'close' column if available, or float columns only.
        """
        # [ìˆ˜ì •] 1. 'close' ì»¬ëŸ¼ì´ ëª…ì‹œì ìœ¼ë¡œ ì¡´ì¬í•˜ë©´ ê·¸ê²ƒë§Œ ì‚¬ìš© (ë‹¨ì¼ ì¢…ëª© OHLCV ë°ì´í„°ì¸ ê²½ìš°)
        if 'close' in prices.columns:
            target_prices = prices[['close']]
        else:
            # [ìˆ˜ì •] 2. ì—¬ëŸ¬ ì¢…ëª©ì¸ ê²½ìš°: int(íƒ€ì„ìŠ¤íƒ¬í”„)ë¥¼ ì œì™¸í•˜ê³  float(ê°€ê²©)ë§Œ ì„ íƒ
            target_prices = prices.select_dtypes(include=['float', 'float32', 'float64'])

        # ì„ íƒëœ ë°ì´í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì›ë³¸ì—ì„œ ê°•ì œ ë³€í™˜ ì‹œë„
        if target_prices.empty:
             target_prices = prices.apply(pd.to_numeric, errors='coerce')

        if method == 'log':
            # ë¡œê·¸ ìˆ˜ìµë¥ : ln(Pt / Pt-1)
            with np.errstate(divide='ignore', invalid='ignore'):
                returns = np.log(target_prices / target_prices.shift(1))
        else:
            # ë‹¨ìˆœ ìˆ˜ìµë¥ : (Pt - Pt-1) / Pt-1
            returns = target_prices.pct_change()
        
        # ë¬´í•œëŒ€(inf)ë‚˜ NaN ê°’ ì œê±°
        return returns.replace([np.inf, -np.inf], np.nan).dropna()

class MarketBenchmark:
    """
    Load or Create market benchmark indices.
    """
    
    @staticmethod
    def load_benchmark_from_file(
        data_dir: str,
        exchange: str,
        frequency: str = "1m"
    ) -> Optional[pd.Series]:
        """
        Load pre-calculated benchmark from parquet file.
        Structure: data/benchmark/{exchange}/[upbit_]benchmark_{freq}.parquet
        """
        base_path = Path(data_dir) / "benchmark" / exchange
        
        # ì´ë¯¸ì§€ ê¸°ë°˜ íŒŒì¼ëª… ê·œì¹™ ì ìš©
        if exchange == 'upbit':
            filename = f"upbit_benchmark_{frequency}.parquet"
        else:
            # binance ë° ê¸°ë³¸ê°’
            filename = f"benchmark_{frequency}.parquet"
            
        filepath = base_path / filename
        
        if not filepath.exists():
            print(f"âš ï¸  Benchmark file not found: {filepath}")
            return None
            
        try:
            print(f"ğŸ“‰ Loading Market Benchmark: {filename}")
            # Parquet íŒŒì¼ ì½ê¸°
            df = pd.read_parquet(filepath)
            
            # ì¸ë±ìŠ¤(ë‚ ì§œ) ì²˜ë¦¬ (CryptoDataLoaderì™€ ë™ì¼í•œ ë¡œì§)
            if 'datetime' in df.columns:
                df['datetime'] = pd.to_datetime(df['datetime'])
                df.set_index('datetime', inplace=True)
            elif 'timestamp' in df.columns:
                df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')
                df.set_index('datetime', inplace=True)
            elif 'open_time' in df.columns:
                df['datetime'] = pd.to_datetime(df['open_time'], unit='ms')
                df.set_index('datetime', inplace=True)
                
            # 'close' ê°€ê²©ì„ ë²¤ì¹˜ë§ˆí¬ ì§€ìˆ˜ë¡œ ì‚¬ìš© (ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì»¬ëŸ¼ ì‚¬ìš©)
            if 'close' in df.columns:
                series = df['close']
            else:
                series = df.iloc[:, 0]
                
            series.name = 'Market'
            return series
            
        except Exception as e:
            print(f"âŒ Error loading benchmark {filepath}: {e}")
            return None

    # (ê¸°ì¡´ ê³„ì‚° ë¡œì§ì€ ë°±ì—…ìš©ìœ¼ë¡œ ë‚¨ê²¨ë‘ê±°ë‚˜ ì‚­ì œí•˜ì…”ë„ ë©ë‹ˆë‹¤)
    @staticmethod
    def create_equal_weighted_index(prices: pd.DataFrame, name: str = 'Market') -> pd.Series:
        normalized = prices / prices.iloc[0] * 100
        index = normalized.mean(axis=1)
        index.name = name
        return index


def prepare_data_for_analysis(
    data_dir: str = "data",
    exchange: str = "binance",
    symbols: Optional[List[str]] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    min_observations: int = 10000
) -> Tuple[pd.DataFrame, pd.Series]:
    """
    Prepare data loading benchmark from file.
    """
    config = DataConfig(
        data_dir=data_dir,
        exchange=exchange,
        frequency="1m",
        start_date=start_date,
        end_date=end_date
    )
    
    loader = CryptoDataLoader(config)
    
    # 1. Load Available Symbols
    available = loader.get_available_symbols()
    if not available:
        raise ValueError(f"No data found in {config.data_dir}/{exchange}")
    
    print(f"ğŸ“Š Found {len(available)} symbols in {exchange}")
    
    if symbols:
        symbols_to_load = [s for s in symbols if s in available]
    else:
        symbols_to_load = available
    
    print(f"ğŸ“¥ Loading {len(symbols_to_load)} asset symbols...")
    
    # 2. Load Asset Prices
    prices = loader.load_multiple_symbols(
        symbols_to_load, 
        start_date, 
        end_date,
        price_column='close'
    )
    
    if prices.empty:
        raise ValueError("No asset data loaded")
        
    # Filter by minimum observations
    valid_symbols = [col for col in prices.columns if prices[col].notna().sum() >= min_observations]
    prices = prices[valid_symbols]
    print(f"âœ… Loaded assets: {len(valid_symbols)} symbols")

    # 3. Load Market Benchmark from File (ìˆ˜ì •ëœ ë¶€ë¶„)
    market_prices = MarketBenchmark.load_benchmark_from_file(
        data_dir=data_dir,
        exchange=exchange,
        frequency="1m"
    )
    
    if market_prices is None:
        raise ValueError(f"Critical: Could not load benchmark file for {exchange}")

    # 4. Align Data (ì¤‘ìš”: ìì‚° ë°ì´í„°ì™€ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì˜ ë‚ ì§œë¥¼ êµì§‘í•©ìœ¼ë¡œ ë§ì¶¤)
    # ë²¤ì¹˜ë§ˆí¬ì™€ ê°œë³„ ìì‚°ì˜ ê¸°ê°„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê³µí†µëœ ê¸°ê°„ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
    common_index = prices.index.intersection(market_prices.index)
    
    if len(common_index) == 0:
        raise ValueError("No overlapping dates between Assets and Benchmark!")
        
    prices = prices.loc[common_index]
    market_prices = market_prices.loc[common_index]
    
    print(f"ğŸ”— Aligned Data Range: {prices.index[0]} to {prices.index[-1]}")
    print(f"   Total Observations: {len(prices):,}")
    
    return prices, market_prices